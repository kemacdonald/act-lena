---
title: "LSTM implementation"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, warning = F, message = F)
```

## Set up LSTM language model

Neural language models are designed to learn how to predict the next word in a sequence given the prior context. In our case, words are cluster assignments for each 100-ms segment of pitch contours.

This implementation of the LSTM below is borrowed from this [tutorial] (https://keras.rstudio.com/articles/examples/lstm_text_generation.html) where they implement a character-level neural language model. 

```{r libraries}
library(R.matlab)
library(keras); library(tfruns); library(cloudml); library(here); library(tidyverse)
source(here("code/00_helper_functions/lstm-helpers.R"))

# set up paths to training sequences for original and new pipepline
read_path <- "data/03_summaries"
read_path_rasanen <- "data/03_summaries/rasanen_2018"
rasanen_results <- "results_19-Oct-2017 21_07_23_ManyBabies_usesyllables0_framesize_100.mat"
```

## Read data and set up parameters

```{r model parameters}
use_rasanen <- FALSE
lstm_units <- 30
lstm_output_dim <- 30
n_epochs <- 150

early_stop <- callback_early_stopping(monitor = "val_loss", min_delta = 0.0001,
                                      patience = 3, verbose = 0, mode = "auto")
```


```{r read data}
if (use_rasanen) {
  
  input_length <- 10
  n_clusters <- 24
  input_shape <- n_clusters + 1 # size of vocabulary + 1
  
  d_meta <- readMat(here(read_path_rasanen, rasanen_results))
  d_preds <- readMat(here(read_path_rasanen, "preds_out.mat"))
  d <- readMat(here(read_path_rasanen, "lstm_traindata.mat"))
  
  train_in <- d$train.in
  train_out <- d$train.out
  test_in <- d$test.in
  test_out <- d$test.out
  
} else {
  
  d <- read_rds(here(read_path, "lena-pred-lstm-train-test.rds"))
  unique_clusters <- d$train_data$next_cluster %>% unique() %>% unlist() %>% sort()
  n_clusters <- length(unique_clusters)
  input_shape <- length(unique_clusters) + 1 # size of vocabulary
  input_length <- d$train_data$prev_cluster_seq[[1]] %>% length()
  
  # vectorize data for passing to LSTM
  train_in <- vectorize_data(d$train_data, data_type = "input")
  train_out <- vectorize_data(d$train_data, data_type = "output")
  test_in <- vectorize_data(d$test_data, data_type = "input")
  test_out <- vectorize_data(d$test_data, data_type = "output")
  
}
```

## Model Definition 

```{r}
model <- keras_model_sequential()

model %>%
  layer_embedding(
    input_dim = input_shape, 
    output_dim = lstm_output_dim, 
    input_length = input_length
    ) %>% 
  layer_lstm(units = lstm_units, input_shape = c(input_length, input_shape)) %>%
  layer_dense(n_clusters, activation = "softmax")

model %>% compile(
  loss = "categorical_crossentropy", 
  optimizer = 'rmsprop',
  metrics = list('accuracy')
)

summary(model)
```

## Train the model

```{r}
m_fit <- model %>% 
  fit(train_in, train_out,
      batch_size = 10,
      epochs = 60,
      validation_split = 0.3, # ask Okko about validation split
      shuffle = TRUE,
      callbacks = early_stop
      ) 
```

Visualize the change in loss function during training.

```{r}
plot(m_fit)
```

## Evaluate the model

```{r}
results <- model %>% keras::evaluate(test_in, test_out)
results
```

## Generate predictions 

Get a predicted probability distribution over each cluster in test sequences and save these predictions for later analysis, adding all relevant metadata. 

```{r}
preds <- model %>% predict(test_in)
```

Tidy up the model predictions for later analysis.

```{r}
d_preds <- preds %>% as_tibble(.name_repair = "universal") %>% janitor::clean_names()
colnames(d_preds) <- colnames(d_preds) %>% str_replace("x", "shape_")

d_preds %>% 
  mutate(seg_id = d$test_data$next_cluster_seg_id %>% as.character(),
         speech_register = d$test_data$next_cluster_speech_register %>% as.character(),
         time_bin_id = d$test_data$next_cluster_time_bin_id %>% as.character(),
         target_cluster = d$test_data$next_cluster %>% as.character(),
         dataset = d$test_data$next_cluster_dataset %>% as.character()) %>% 
  select(seg_id, dataset, speech_register, time_bin_id, target_cluster, 
         everything()) -> d_preds

# tidy the predictions
d_preds_tidy <- d_preds %>% gather(key = "cluster_shape", value = "prob_mass", shape_1:shape_8)
```

Save predictions

```{r}
if (use_rasanen) {
  fst::write_fst(d_preds_tidy, here(read_path, "lena-pred-lstm-preds-rasanen.fst"))  
} else {
  fst::write_fst(d_preds_tidy, here(read_path, "lena-pred-lstm-preds.fst"))  
}
```
